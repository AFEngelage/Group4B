{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PpLWCBFNuons"
   },
   "source": [
    "### Supermarket data science case study - Exploring first data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 698,
     "status": "ok",
     "timestamp": 1608147217503,
     "user": {
      "displayName": "pi1234",
      "photoUrl": "",
      "userId": "00485952581093036663"
     },
     "user_tz": -60
    },
    "id": "r_EATkKHugiZ"
   },
   "outputs": [],
   "source": [
    "#pip install --user pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPQo8za16cQT"
   },
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 696,
     "status": "ok",
     "timestamp": 1608147217504,
     "user": {
      "displayName": "pi1234",
      "photoUrl": "",
      "userId": "00485952581093036663"
     },
     "user_tz": -60
    },
    "id": "OlwScieYRTmf",
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dm7aDtim6guo"
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 695,
     "status": "ok",
     "timestamp": 1608147217505,
     "user": {
      "displayName": "pi1234",
      "photoUrl": "",
      "userId": "00485952581093036663"
     },
     "user_tz": -60
    },
    "id": "f1PDhgg8ZBbf",
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def f_concat(l_input):\n",
    "\n",
    "    # Initialize.\n",
    "    dummy = \"\"\n",
    "    n_len = len(l_input)\n",
    "    \n",
    "    if n_len == 1:\n",
    "        return l_input[0]\n",
    "\n",
    "    # Loop through text elements.\n",
    "    for i in range(n_len-1):\n",
    "        dummy = dummy + l_input[i] + \", \"\n",
    "\n",
    "    # Append last element.\n",
    "    dummy = dummy + \"and \" + l_input[n_len-1]\n",
    "\n",
    "    # Return result.\n",
    "    return dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def f_describe(df_input, n_top = 10):\n",
    "    \n",
    "    print(\"First \" + str(n_top) + \" rows in de data:\")\n",
    "    display(df_input.head(n_top))\n",
    "     \n",
    "    \n",
    "    df_numeric = df_input.select_dtypes(include = ['uint8', 'uint16', 'uint32', 'uint64', 'int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64'])\n",
    "\n",
    "    if len(df_numeric.columns):\n",
    "        print(\"Numerical data:\")\n",
    "        display(df_numeric.describe())\n",
    "\n",
    "        \n",
    "    df_textual = df_input.select_dtypes(include = ['category', 'object', 'bool'])\n",
    "\n",
    "    if len(df_textual.columns):\n",
    "        print(\"Textual data:\")\n",
    "        display(df_textual.describe())\n",
    "        \n",
    "        \n",
    "    v_na = [col + \" (\" + str(df[col].isna().sum()) + \", \" + str(round(100 * df[col].isna().sum() / df.shape[0], 1)) + \"%)\" for col in df.columns if df[col].isna().sum() > 0]\n",
    "\n",
    "    if len(v_na) > 0:\n",
    "        print(\"Features and their number of missing values:\")\n",
    "        display(f_concat(v_na))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downcast and transform data\n",
    "Update formatting of features to optimize memory and standardize column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def standardize_column_names(s):\n",
    "    return s.replace(\" \", \"\")\n",
    "\n",
    "def optimize_memory(df):   \n",
    "    # Change: Objects to Categorical.                                               #WHEN needed to transform Objects to Categorical?\n",
    "    # object_cols = df.select_dtypes(include=\"object\").columns\n",
    "    # if not object_cols.empty:\n",
    "    #     print(\"Change: Objects to Categorical\")\n",
    "    #     df[object_cols] = df[object_cols].astype(\"category\")\n",
    "\n",
    "    # Change: Convert integers to smallest unsigned integer and floats to smallest.\n",
    "    for old, new in [(\"integer\", \"unsigned\"), (\"float\", \"float\")]:\n",
    "        print(\"Change: \" + old + \" --> \" + new)\n",
    "        for col in df.select_dtypes(include=old).columns:\n",
    "            df[col] = pd.to_numeric(df[col], downcast=new)\n",
    "\n",
    "    return df\n",
    "\n",
    "def month_year_to_int(df, i):\n",
    "    # Change: Month and Year to integer\n",
    "    if(i == 0):\n",
    "        print(\"Change: Month and Year to integer\")\n",
    "        df = df.astype({\"month\": int, \"year\": int})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform date-related columns to datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "##HOW TO DOCUMENT? Findings regarding dataset, template or normalized structure? \n",
    "    #day/month/year, UTC, date = object Dtypes\n",
    "\n",
    "\n",
    "# Convert datasets to time series\n",
    "def transform_date_to_datetime(df, i):\n",
    "    if i == 0:\n",
    "        print(\"Change: Transformed 'year', 'month', 'day' columns to Datetime feature\")\n",
    "        df['date'] = pd.to_datetime(df[['year', 'month', 'day']])    \n",
    "\n",
    "        #print(\"Change: Dropped 'year', 'month', 'day' columns and transformed to Datetime feature\")\n",
    "        #df.drop(columns=['day', 'month', 'year'])                                                      #To do: Not dropping while running code\n",
    "\n",
    "    else: #holiday, transactions and oil \n",
    "        if 'date' in df.columns:\n",
    "            print(\"Change: Transformed 'date' column to Datetime Dtype\") #datetime.datetime.fromisoformat()\n",
    "            df['date']=pd.to_datetime(df['date']) \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data from local PATH\n",
    "Import data trough pipeline to downcast the data and transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XaDlRA_wRK0U",
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def f_get_data(i=0):\n",
    "\n",
    "    # Define path.\n",
    "    c_path = 'C:/Users/J.Heuvelmans/OneDrive - Brain Research Center/Documenten/EAISI/2024Supermarket/Code/data/raw/'\n",
    "    \n",
    "    # Identify file.\n",
    "    v_file = (\"history-per-year\",   # 0\n",
    "              \"history_aggregated\", # 1\n",
    "              \"holidays_events\",    # 2\n",
    "              \"items\",              # 3\n",
    "              \"oil\",                # 4\n",
    "              \"stores\",             # 5\n",
    "              \"transactions\")       # 6\n",
    "\n",
    "    # Load data.   \n",
    "    df = (\n",
    "         pd.read_parquet(c_path + v_file[i] + \".parquet\")\n",
    "         .rename(columns = standardize_column_names)\n",
    "         .pipe(optimize_memory)\n",
    "         .pipe(month_year_to_int, i)\n",
    "         .pipe(transform_date_to_datetime, i)\n",
    "    )\n",
    "    \n",
    "    # Return data.\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zXWuFInRee5"
   },
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "df = f_get_data(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "f_describe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "a = df['onpromotion'].value_counts()\n",
    "b = df['onpromotion'].isna().sum()\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(a+b)\n",
    "perc_missing = b/125497040 * 100\n",
    "perc_false = 96028767/125497040 * 100\n",
    "perc_true = 7810622/125497040 *100\n",
    "\n",
    "print(perc_missing)\n",
    "print(perc_false)\n",
    "print(perc_true)\n",
    "total = perc_missing + perc_false + perc_true\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_maxsales = df[df['unit_sales'] > 10000]\n",
    "df_maxsales\n",
    "\n",
    "df_850389 = df[df['item_nbr']==850389]\n",
    "df_850389\n",
    "\n",
    "import altair as alt\n",
    "\n",
    "hist = alt.Chart(df_850389).mark_bar().encode(\n",
    "    alt.X('date', title='date'),\n",
    "    alt.Y('unit_sales', title='unit_sales')\n",
    ").properties(\n",
    "    title='Sales of 850389',\n",
    "    width=600,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "hist.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below calculation of total sales per store: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_total_sales(df):\n",
    "    results = []\n",
    "    for i in range(1, 55):\n",
    "        df_store = df[df['store_nbr']==i]\n",
    "        total_sales = df_store['unit_sales'].sum()\n",
    "        results.append({'store_nbr': i, 'total_sales': total_sales})\n",
    "    df_totals = pd.DataFrame(results)\n",
    "    df_totals = df_totals.sort_values(by='total_sales', ascending=False).reset_index(drop=True)                                                                                                                                                                                                                                                                                                                                     \n",
    "    return df_totals\n",
    "\n",
    "df_totals = calc_total_sales(df)\n",
    "\n",
    "import altair as alt\n",
    "\n",
    "hist = alt.Chart(df_totals).mark_bar().encode(\n",
    "    alt.X('store_nbr:O', title='Store Number', sort='-y'),\n",
    "    alt.Y('total_sales:Q', title='Total Sales')\n",
    ").properties(\n",
    "    title='Histogram of Total Sales',\n",
    "    width=600,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "hist.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRjToxz4Rb3h"
   },
   "source": [
    "### Some Statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11505,
     "status": "ok",
     "timestamp": 1608136751408,
     "user": {
      "displayName": "pi1234",
      "photoUrl": "",
      "userId": "00485952581093036663"
     },
     "user_tz": -60
    },
    "id": "HV1Ee1SwSefa",
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "outputId": "d77a35c0-17b1-4328-f216-9a9d85c81220"
   },
   "outputs": [],
   "source": [
    "print(\"The data\\n\")\n",
    "print(f\"-> Contains:                {round(df.shape[0]/1e6, 1)} million observations and {df.shape[1]} features.\\n\")\n",
    "print(f\"-> Contains:                {df.shape[0]} observations and {df.shape[1]} features.\\n\")\n",
    "print(f\"-> Have feature names:      {f_concat(df.columns)}.\\n\")\n",
    "print(f\"-> Has optimized size of    {round(sys.getsizeof(df)/1024/1024/1024, 2)} GB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = f_get_data(0)\n",
    "#f_describe(df)\n",
    "\n",
    "#df.head()\n",
    "#df.tail(10)\n",
    "df.sample(20)\n",
    "#df.info()\n",
    "#df.describe()\n",
    "#df.nunique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "df = f_get_data(1)\n",
    "#f_describe(df)                             #To do: investigate transforming datetime64[us, UTC] \t2014-09-24 00:00:00+00:00 to normal datetime\n",
    "df.info()\n",
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "df = f_get_data(2)\n",
    "f_describe(df)\n",
    "df.info()\n",
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "df = f_get_data(3)\n",
    "f_describe(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "df = f_get_data(4)\n",
    "f_describe(df)\n",
    "df.info()\n",
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "df = f_get_data(5)\n",
    "f_describe(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "df = f_get_data(6)\n",
    "f_describe(df)\n",
    "df.info()\n",
    "df.sample(20)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP1XEh6OeJMgPK4tWBSiOU8",
   "collapsed_sections": [],
   "mount_file_id": "1tas4gpn15avV6RH91pDuPfl4mfnjqven",
   "name": "Copy of 2020 12 13 - EyeOn Supermarket - v1.ipynb",
   "provenance": [
    {
     "file_id": "1tas4gpn15avV6RH91pDuPfl4mfnjqven",
     "timestamp": 1608148229653
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
