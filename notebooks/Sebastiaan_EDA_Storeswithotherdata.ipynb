{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "file_path_df_035_join = r'C:\\Users\\sebas\\OneDrive\\Documenten\\GitHub\\Supermarketcasegroupproject\\Group4B\\data\\interim\\df_035_join.parquet'\n",
    "\n",
    "\n",
    "df_aggregated_sales = pd.read_parquet(file_path_df_035_join)\n",
    "\n",
    "df_aggregated_sales['date'] = pd.to_datetime(df_aggregated_sales[['month', 'year']].assign(DAY=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_aggregated_sales1 = df_aggregated_sales[(df_aggregated_sales['store_nbr'] == 1)&df_aggregated_sales([df_aggregated_sales['date'] == '2013-01-01')]\n",
    "df_aggregated_sales1 = df_aggregated_sales[(df_aggregated_sales['store_nbr'] == 1) & (df_aggregated_sales['date'] == '2013-01-01')]\n",
    "\n",
    "#df [ ( df['store_nbr'] == 25 ) & (df['day'] == 1) & (df['month'] == 1) & (df['year'] == 2013) ] .shape[0]\n",
    "\n",
    "df_aggregated_sales1.head(1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregated_sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "df_aggregated_sales_store = df_aggregated_sales.groupby(['store_nbr', 'date','year']).agg({\n",
    "                                'type': 'first', \n",
    "                                'cluster': 'first', \n",
    "                                'city': 'first', \n",
    "                                'state': 'first',\n",
    "                                'unit_sales': 'sum'}).reset_index()\n",
    "df_aggregated_sales_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.1 - Total sales in units is generated by \n",
    "\n",
    "When looking into the data, we first delved deeper into just the amount of stores per city. Here, we found that especially Quito is overrepresented by the amount of supermarkets located there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregated_sales_type = df_aggregated_sales.groupby('type')['unit_sales'].sum()/1000\n",
    "\n",
    "df_aggregated_sales_type = df_aggregated_sales_type.sort_values(ascending=False)\n",
    "\n",
    "df_aggregated_sales_type2 = pd.DataFrame(df_aggregated_sales_type)\n",
    "\n",
    "df_aggregated_sales_type2['Percentage'] = df_aggregated_sales_type2/df_aggregated_sales_type2.sum()*100\n",
    "\n",
    "df_aggregated_sales_type2 = round(df_aggregated_sales_type2,2)\n",
    "\n",
    "df_aggregated_sales_type2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.1 - Total sales per store by month over all time periods in the dataset - Some stores are relatively new and might be excluded for further analysis\n",
    "\n",
    "The first step we take when combining the store data with the transaction date is to look if there's unit sale data for each store available. Although we have data available for each store, some stores don't have data for all the dates in the dataset. Most likely, these stores are new, this makes forecasting for these store less convenient and as this is our first forecast for Corporacion Favorita, we rather have a more generalizable store to choose from (having a higher impact on business as the likelihood of giving a more accurate forecast is higher)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "g = sns.relplot(\n",
    "    data=df_aggregated_sales_store,\n",
    "    x=\"date\", y=\"unit_sales\", col=\"store_nbr\", hue=\"store_nbr\",\n",
    "    kind=\"line\", palette=\"crest\", linewidth=4, zorder=5,\n",
    "    col_wrap=3, height=2, aspect=1.5, legend=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.1 - Total sales per store by month over all time periods in the dataset - It seems not only new stores miss data but also older stores have missing data\n",
    "\n",
    "The only way to really check if stores have data for all the months in the dataset is to count the amount of months available of data. Thereby we find that 12 stores don't have data for the full timeperiod. \n",
    "\n",
    "Stores that are relatively new:\n",
    "\n",
    "Started in 2013\n",
    "Store 36 (per May)\n",
    "\n",
    "Started in 2014\n",
    "Store 53 (per May)\n",
    "\n",
    "Started in 2015\n",
    "Store 20 (per Feb)\n",
    "Store 21 (per Jul)\n",
    "Store 22 (per Oct)\n",
    "Store 29 (per Mar)\n",
    "Store 42 (per Aug)\n",
    "\n",
    "Started in 2017\n",
    "Store 52 (per Apr)\n",
    "\n",
    "Stores that have missing data (might be closed for one or multiple months)\n",
    "\n",
    "2014 - Store number 24\n",
    "2015 - Store number 12\n",
    "2016 - Store number 18 and 25\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "row_count_per_store = df_aggregated_sales_store['store_nbr'].value_counts()\n",
    "\n",
    "row_count_per_store = row_count_per_store.sort_values(ascending=True)\n",
    "\n",
    "print(row_count_per_store)\n",
    "\n",
    "type(row_count_per_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "row_count_per_store56 = row_count_per_store[row_count_per_store == 56]\n",
    "row_count_per_store56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "df_store_25 = df_aggregated_sales_store[df_aggregated_sales_store['store_nbr'] == 18]\n",
    "df_store_25.plot.line(x='date', y='unit_sales', figsize=(10, 6))\n",
    "\n",
    "#df_store_25_filtered = df_store_25[df_store_25['unit_sales'] <= 1000]\n",
    "#df_store_25_filtered.plot.line(x='date', y='unit_sales', figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "# Pivot the dataframe to have store_nbr as rows, date as columns, and unit_sales as values\n",
    "pivot_df = df_aggregated_sales_store.pivot(index='store_nbr', columns='date', values='unit_sales')\n",
    "\n",
    "# Set the size of the figure\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "# Create the heatmap\n",
    "heatmapdatestoresales = sns.heatmap(pivot_df, cmap='Blues', annot=False, fmt='.1f')\n",
    "\n",
    "# Set the labels for x and y axis\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Store Number')\n",
    "\n",
    "heatmapdatestoresales.xaxis.tick_bottom()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the heatmap we can atleast observe two things. First, we can see the several stores that are missing data. Second, we can see that several stores have significant higher sales in terms of units sold (store 3 and 44,45,46,47,48,49). Now, we can delve further into seeing wether the missing data influences the type and clusters of stores by comparing the original data to a filtered dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.2 - For investigating the types and clusters further, we drop the stores that don't have data for the full timeline.\n",
    "\n",
    "In that way, we don't have to worry about these stores interfering with the results on any insights of type and cluster. However, to see if the missing data actually has an effect on the clusters and types, we first will make a boxplot on botht he original data (without filtering) as well as a filtered set.\n",
    "\n",
    "Within the boxplot one can see the range of total unit_sales per cluster (a range determined by the unit sales per store within the cluster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First boxplot is made on the original data (not the filtered)\n",
    "sns.set_theme(style=\"ticks\", palette=\"rocket\")\n",
    "\n",
    "# Here i make a order list\n",
    "order = df_aggregated_sales_store.groupby(['cluster'])['unit_sales'].max().sort_values(ascending=False).index\n",
    "\n",
    "# Draw a nested boxplot to show bills by day and time\n",
    "sns.boxplot(x=\"cluster\", y=\"unit_sales\",\n",
    "            hue=\"type\",palette='Set2',\n",
    "            data=df_aggregated_sales_store,\n",
    "            order=order,\n",
    "            width = 0.5,\n",
    "            dodge=False,\n",
    "            showmeans= True).set_title(\"Total unit sales and distribution per cluster and type - Unfiltered\", fontsize=17)\n",
    "plt.ylabel(\"Unit sales in millions\", fontsize=13)\n",
    "plt.xlabel(\"Cluster\", fontsize=13)\n",
    "# sns.despine(offset=1, trim=True)\n",
    "# sns.stripplot(dodge = True)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregated_sales_store.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregated_sales_store_filtered = df_aggregated_sales_store.merge(row_count_per_store56.astype(df_aggregated_sales_store['store_nbr'].dtype), left_on= 'store_nbr', right_index=True, how='inner')\n",
    "\n",
    "df_aggregated_sales_store_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregated_sales_store_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second boxplot is made on the filtered data\n",
    "sns.set_theme(style=\"ticks\", palette=\"rocket\")\n",
    "\n",
    "# Here i make a order list\n",
    "order = df_aggregated_sales_store_filtered.groupby(['cluster'])['unit_sales'].max().sort_values(ascending=False).index\n",
    "\n",
    "# Draw a nested boxplot to show bills by day and time\n",
    "sns.boxplot(x=\"cluster\", y=\"unit_sales\",\n",
    "            hue=\"type\",palette='Set2',\n",
    "            data=df_aggregated_sales_store_filtered,\n",
    "            order=order,\n",
    "            width=0.5,\n",
    "            dodge=False,\n",
    "            showmeans= True).set_title(\"Total unit sales and distribution per cluster and type - Filtered\", fontsize=17)\n",
    "plt.ylabel(\"Unit sales in millions\", fontsize=13)\n",
    "plt.xlabel(\"Cluster\", fontsize=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do\n",
    "\n",
    "1- Average sales per city?\n",
    "2- Sales per store (with color for city?)\n",
    "3- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregated_sales_store_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregated_sales_store_filtered_sum = df_aggregated_sales_store_filtered.groupby(['store_nbr',]).agg({\n",
    "    'city' :'first',\n",
    "    'state':'first',\n",
    "    'type':'first',\n",
    "    'unit_sales' : 'sum'}).reset_index()\n",
    "df_aggregated_sales_store_filtered_sum = df_aggregated_sales_store_filtered_sum.astype({'store_nbr':str})\n",
    "\n",
    "df_aggregated_sales_store_filtered_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe to unit_sales\n",
    "df_aggregated_sales_store_filtered_sum =df_aggregated_sales_store_filtered_sum.sort_values(by = 'unit_sales', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 10))  # Adjust the width and height as desired\n",
    "\n",
    "# Create the barplot\n",
    "sns.barplot(data=df_aggregated_sales_store_filtered_sum, x='unit_sales', y='store_nbr', hue='city', palette='pastel', width = 0.5)\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title('Unit Sales by Store Number')\n",
    "plt.xlabel('Unit Sales')\n",
    "plt.ylabel('Store Number')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(rc={'figure.figsize':(20.7,12.27)},style=\"white\", palette=None)\n",
    "sns.scatterplot(\n",
    "    data = df_aggregated_sales_store_filtered_sum, x=\"city\", y='store_nbr', hue ='unit_sales', size = 'unit_sales',  \n",
    "    sizes =(20,1000), legend = \"brief\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the percentage of unit_sales per store in relation to the total unit_sales\n",
    "df_aggregated_sales_store_filtered_sum['Percentage'] = (df_aggregated_sales_store_filtered_sum['unit_sales'] / df_aggregated_sales_store_filtered_sum['unit_sales'].sum())*100\n",
    "\n",
    "# Make a cumulative sum of the amount of stores\n",
    "df_aggregated_sales_store_filtered_sum['Cum_sum'] = df_aggregated_sales_store_filtered_sum['unit_sales'].cumsum()\n",
    "\n",
    "# Make a cumulative percentage column\n",
    "df_aggregated_sales_store_filtered_sum['Cumulative Percentage'] = round(100*df_aggregated_sales_store_filtered_sum.Cum_sum/df_aggregated_sales_store_filtered_sum['unit_sales'].sum(),2)\n",
    "\n",
    "df_aggregated_sales_store_filtered_sum.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_aggregated_sales_store_filtered_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.3 - Find out of the stores that are filtered out have a big impact on sales units and thus alternative ways should be found\n",
    "\n",
    "Although we filtered out the stores in the former steps, we have to find out if filtering out was the right decision to take. They might have a big impact on total sales and therefore excluding them might have not been the right decision to make. Therefore in this step i will analyse the impact of the stores with missing data on the total sales units.\n",
    "\n",
    "Step 1 - Make a aggregated dataset for sales per store over the full timeline and mark the stores according to: 1) stores that have data available for all data points, 2) stores that miss a lot of data (started later), 3) stores that miss some data. \n",
    "\n",
    "Step 2 - Plot the relative size of sales of the combination of missing data categories 2 and 3 in relation to the total.\n",
    "\n",
    "Step 3 - For new stores, also look into the last year/months of sales to see if they are relatively big (they might be new but exceptionally big. Thus, being important for further exploration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impact of new stores on total sales \n",
    "# What new stores might be interesting?\n",
    "# Look at daily level sales data with stores to see if you can find interesting insights. \n",
    "# Oil price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Make aggregated data set for sales per store over the full timeline and mark stores according to  1) stores that have data available for all data points, 2) stores that miss a lot of data (started later), 3) stores that miss some data. \n",
    "\n",
    "df_aggregated_sales_store_unfiltered = df_aggregated_sales_store.merge(row_count_per_store.astype(df_aggregated_sales_store['store_nbr'].dtype), left_on= 'store_nbr', right_index=True, how='inner')\n",
    "\n",
    "# Rename the result of the count column to a monthcount (as it stands for monthcount)\n",
    "df_aggregated_sales_store_unfiltered = df_aggregated_sales_store_unfiltered.rename(columns={'count':'monthcount'})\n",
    "\n",
    "# Aggregate the dataframe on sales and store level from a month basis to a total basis\n",
    "df_aggregated_sales_store_unfiltered_sum = df_aggregated_sales_store_unfiltered.groupby(['store_nbr','monthcount']).agg({\n",
    "    'city' :'first',\n",
    "    'state':'first',\n",
    "    'type':'first',\n",
    "    'unit_sales' : 'sum'}).reset_index()\n",
    "df_aggregated_sales_store_unfiltered_sum = df_aggregated_sales_store_unfiltered_sum.astype({'store_nbr':str})\n",
    "\n",
    "# Assign a value of 0 to the stores that have data available for all data points and 0 to the stores that miss data.\n",
    "df_aggregated_sales_store_unfiltered_sum['store_status'] = np.where(df_aggregated_sales_store_unfiltered_sum['monthcount'] == 56, 0, 1)\n",
    "df_aggregated_sales_store_unfiltered_sum['dummy'] = 1\n",
    "\n",
    "df_aggregated_sales_store_unfiltered_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Plot the relative size of sales of the combination of missing data categories 2 and 3 in relation to the total.\n",
    "\n",
    "alt.Chart(df_aggregated_sales_store_unfiltered_sum).mark_bar(size = 40).encode(\n",
    "    x=alt.X('sum(unit_sales)').stack(\"normalize\"),\n",
    "    y='dummy',\n",
    "    color='store_status'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out the real percentage of sales for both categories\n",
    "df_aggregated_sales_store_unfiltered_storestatus_sum = df_aggregated_sales_store_unfiltered_sum.groupby(['store_status']).sum(['unit_sales']).reset_index()\n",
    "\n",
    "df_aggregated_sales_store_unfiltered_storestatus_sum['Percentage'] = (df_aggregated_sales_store_unfiltered_storestatus_sum['unit_sales'] / df_aggregated_sales_store_unfiltered_storestatus_sum['unit_sales'].sum())*100\n",
    "\n",
    "df_aggregated_sales_store_unfiltered_storestatus_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does this differ when we look at one of the last months of data?\n",
    "\n",
    "df_aggregated_sales_store_july2017 = df_aggregated_sales_store[df_aggregated_sales_store['date'] == '2017-07-01']\n",
    "\n",
    "df_aggregated_sales_store_july2017 = df_aggregated_sales_store_july2017[['store_nbr','unit_sales','date']]\n",
    "\n",
    "df_aggregated_sales_store_july2017['store_nbr'] = df_aggregated_sales_store_july2017['store_nbr'].astype('str')\n",
    "\n",
    "df_aggregated_sales_store_july2017_status = df_aggregated_sales_store_july2017.merge(df_aggregated_sales_store_unfiltered_sum[['store_nbr','store_status','dummy']].astype(df_aggregated_sales_store_july2017['store_nbr'].dtype), left_on='store_nbr',right_on= 'store_nbr', how='inner')\n",
    "\n",
    "df_aggregated_sales_store_july2017_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregated_sales_store_july2017_status_grouped = df_aggregated_sales_store_july2017_status.groupby('store_status').sum('unit_sales')\n",
    "\n",
    "df_aggregated_sales_store_july2017_status_grouped['Percentage'] = (df_aggregated_sales_store_july2017_status_grouped['unit_sales']/df_aggregated_sales_store_july2017_status_grouped['unit_sales'].sum())*100\n",
    "\n",
    "df_aggregated_sales_store_july2017_status_grouped"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
